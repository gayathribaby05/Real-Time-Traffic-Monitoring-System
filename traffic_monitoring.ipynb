{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXj663Dfx87l+WsUESeDkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayathribaby05/Real-Time-Traffic-Monitoring-System/blob/main/traffic_monitoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w5FeE360LDz",
        "outputId": "e7ac4b12-0df3-430f-a4a9-0649e7332156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision opencv-python pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Constants\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/Colab Notebooks/traffic_video.mp4\"\n",
        "RED_LINE_Y = 400  # Adjust based on resolution\n",
        "OUTPUT_VIDEO = \"output_annotated_video.mp4\"\n",
        "LOG_FILE = \"traffic_logs.csv\"\n",
        "\n",
        "# Initialize YOLO model (using pretrained YOLOv5s)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Initialize log storage\n",
        "logs = []\n",
        "\n",
        "# Function to annotate frame\n",
        "def annotate_frame(frame, results, frame_number):\n",
        "    global logs\n",
        "    for *box, conf, cls in results.xyxy[0]:\n",
        "        xmin, ymin, xmax, ymax = map(int, box)\n",
        "        center_y = (ymin + ymax) / 2\n",
        "\n",
        "        # Check if the vehicle crossed the red line\n",
        "        crossed = center_y > RED_LINE_Y\n",
        "        color = (0, 0, 255) if crossed else (0, 255, 0)\n",
        "        status = \"Crossed\" if crossed else \"Safe\"\n",
        "\n",
        "        # Draw bounding box and status\n",
        "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "        cv2.putText(frame, status, (xmin, ymin - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Log the vehicle's status\n",
        "        if crossed:\n",
        "            logs.append({\"Frame\": frame_number, \"Left\": xmin, \"Top\": ymin,\n",
        "                         \"Right\": xmax, \"Bottom\": ymax, \"Status\": status})\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Process video\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = None\n",
        "frame_number = 0\n",
        "\n",
        "# Check if video file is loaded\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Unable to open video file {VIDEO_PATH}\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"End of video or unable to read frame.\")\n",
        "        break\n",
        "\n",
        "    # Initialize video writer only once after reading the first valid frame\n",
        "    if out is None:\n",
        "        if frame is not None:\n",
        "            out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, 60,\n",
        "                                  (frame.shape[1], frame.shape[0]))\n",
        "            print(f\"Video writer initialized: {OUTPUT_VIDEO}\")\n",
        "        else:\n",
        "            print(\"Error: Unable to access frame properties for initialization.\")\n",
        "            break\n",
        "\n",
        "    # Perform detection\n",
        "    results = model(frame)\n",
        "\n",
        "    # Annotate frame\n",
        "    annotated_frame = annotate_frame(frame, results, frame_number)\n",
        "\n",
        "    # Draw the red line\n",
        "    cv2.line(annotated_frame, (0, RED_LINE_Y), (frame.shape[1], RED_LINE_Y), (0, 0, 255), 2)\n",
        "\n",
        "    # Write frame to output\n",
        "    out.write(annotated_frame)\n",
        "    frame_number += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "if out:\n",
        "    out.release()\n",
        "    print(f\"Annotated video saved: {OUTPUT_VIDEO}\")\n",
        "else:\n",
        "    print(\"No output video generated. Please check the input video or processing logic.\")\n",
        "\n",
        "# Save logs to CSV\n",
        "if logs:\n",
        "    df = pd.DataFrame(logs)\n",
        "    df.to_csv(LOG_FILE, index=False)\n",
        "    print(f\"Logs saved: {LOG_FILE}\")\n",
        "else:\n",
        "    print(\"No logs generated. No vehicles crossed the red line.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5g1lU_h0blg",
        "outputId": "d1e30cd1-c307-4095-f14f-f8d7d9f5bfdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ 2024-12-5 Python-3.10.12 torch-2.5.1+cu121 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 134MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Unable to open video file /content/drive/MyDrive/Colab Notebooks/traffic_video.mp4\n",
            "End of video or unable to read frame.\n",
            "No output video generated. Please check the input video or processing logic.\n",
            "No logs generated. No vehicles crossed the red line.\n"
          ]
        }
      ]
    }
  ]
}